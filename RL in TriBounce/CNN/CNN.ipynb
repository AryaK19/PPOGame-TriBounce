{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.0 (SDL 2.28.0, Python 3.11.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from GameForCNN import Tribounce\n",
    "\n",
    "from gymnasium import Env\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from gymnasium.spaces import Discrete,Box\n",
    "\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TribounceEnv(Env):\n",
    "    def __init__(self,render=False):\n",
    "        super().__init__()\n",
    "        self.game = Tribounce(render=render)\n",
    "\n",
    "        self.observation_space = Box(low=0,high=255,shape=(700,1000,3),dtype=np.uint8)\n",
    "        self.action_space = Discrete(3)\n",
    "\n",
    "    def step(self,action):\n",
    "        state,reward,done,info = self.game.run(action=action)\n",
    "        truncated = False\n",
    "        return state,reward,truncated,done,info\n",
    "    \n",
    "    def render(self):\n",
    "        pass\n",
    "    \n",
    "    def reset(self,seed=0):\n",
    "        state = self.game.reset()\n",
    "        info = {}\n",
    "        return state,info\n",
    "    \n",
    "    def close(self):\n",
    "        self.game.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[190, 190, 190],\n",
       "        [190, 190, 190],\n",
       "        [190, 190, 190],\n",
       "        ...,\n",
       "        [190, 190, 190],\n",
       "        [190, 190, 190],\n",
       "        [190, 190, 190]],\n",
       "\n",
       "       [[190, 190, 190],\n",
       "        [190, 190, 190],\n",
       "        [190, 190, 190],\n",
       "        ...,\n",
       "        [190, 190, 190],\n",
       "        [190, 190, 190],\n",
       "        [190, 190, 190]],\n",
       "\n",
       "       [[190, 190, 190],\n",
       "        [190, 190, 190],\n",
       "        [190, 190, 190],\n",
       "        ...,\n",
       "        [190, 190, 190],\n",
       "        [190, 190, 190],\n",
       "        [190, 190, 190]]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = TribounceEnv()\n",
    "env.step(2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common import env_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TribounceEnv()\n",
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGMCAYAAADwaFngAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuIUlEQVR4nO3de3RUVZr+8adyJYCVcEsVEYKojIAgC4nEEmZ6RtJEOuIFVtsy6KCiCAblJkpE8G5oe7V24wUvPYrTg9Kmp1WgEcWgoBICBKERMKCACZdKVEwVBHKt/fvDH6ctg5pASHbi99PrXYs6+606++TQ1OOucyouY4wRAACARSKaewIAAADfR0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANZp1oDy9NNP66yzzlKbNm2Umpqq9evXN+d0AACAJZotoPzlL3/R9OnTdd9992nTpk0aMGCA0tPTVVpa2lxTAgAAlnA11y8LTE1N1UUXXaSnnnpKkhQKhdS9e3fdfvvtmjVrVnNMCQAAWCKqOXZaVVWlgoICZWVlOdsiIiKUlpamvLy8Ov2VlZWqrKx0HodCIR06dEidOnWSy+VqkjkDAIBTY4zR4cOHlZSUpIiIH/8Qp1kCyldffaXa2lp5PJ6w7R6PR59++mmd/uzsbD3wwANNNT0AAHAaFRcXq1u3bj/a0yLu4snKylIgEHCqqKiouacEAABO0hlnnPGTPc2ygtK5c2dFRkaqpKQkbHtJSYm8Xm+d/tjYWMXGxjbV9AAAwGlUn8szmmUFJSYmRoMGDVJubq6zLRQKKTc3Vz6frzmmBAAALNIsKyiSNH36dI0bN04pKSkaPHiw/vCHP6i8vFw33nhjc02pWbRp00Zut1u1tbUKBAKqqalp7ikBAPCDXC6X4uPjFRsbq/Lych05cuT07Mg0oyeffNIkJyebmJgYM3jwYLNu3bp6PS8QCBhJdcrlcpnk5GRzyy23mIcfftjMnj3bXHrppaZNmzYn7G/u6tq1q3nxxRfN/v37za5du8ysWbNMXFxcs8+LoiiKat6KjIw01113nbn//vuN1+s1kkxcXJy59dZbzcMPP2z69etn4uLizOTJk83UqVONy+UyKSkp5re//a3p06ePadeunZk+fbq57bbbGnVeLpfLjBo1ymzcuNGUlJSYd955x6SkpDT4dQKBwE++1zdrQDlZPxRQ+vTpY7Zs2WICgYDZv3+/KS0tNWVlZebhhx82UVFRzf4X7rsVERFhfvvb35rDhw+bp59+2ixZssQEAgFzxRVXNPvcKIqiqOatmJgY85e//MV8+eWXpl+/fiY6OtrMmDHDBAIBM3/+fNOuXTvjdrvNkiVLzIoVK0xERIS54YYbTE1Njbn88stN586dzZYtW8wHH3zQqPM655xzzOeff24+/vhj8+ijj5p9+/aZ3Nxc43a7G/Q69QkozfYRz+kwYsQI9erVS/fff7/++7//W127dtVTTz2lMWPG6KWXXtLu3bt17rnn6vLLL1fnzp21adMmLV++XMeOHVPbtm317//+70pNTVVtba3WrFmjjz76SNXV1Ro2bJjS09O1dOlSDRkyRK+88oqOHj2qK664Queee6727NmjJUuW1LnoV5KGDRumESNG6OWXX9bWrVud7bGxsRoxYoQ2btyoe+65R0lJSVq9erV++ctfatmyZQqFQk35owMAWCoyMlL/+Z//qaysLL322mu69957VV5erri4OH3wwQeKioqSqcd3rsbExOjSSy+Vz+eTMUZr1qzRmjVr6lxa0L59e91xxx06cuSInn/+eVVUVDhjKSkpOvPMMzV79mz99a9/VWRkpCZNmqRu3bpp+/btjXvgp3254zT4oRWUW265xZSXl5tnnnnG9O/f33Tp0sUMHjzYXH755aZDhw6mb9++Ztu2beabb74xBw4cMIFAwMyZM8e0adPGzJs3zxw+fNgcPHjQlJSUmEOHDpmJEycaSWbWrFmmqqrKbN261Xz22Wfm0ksvNUuWLDFlZWVm3759JhAImLffftt06dKlzpxmzZplampqzNVXXx22PSkpyRQXF5s///nPJioqyrRv39588cUX5m9/+5u1H0lRFEVRTVPHV1C++uorM2vWLHPw4EHzyiuvmA4dOjg9CQkJJi8vz2zatKleKyjjx483gUDA+P1+4/f7zddff23Gjh1bZ98ej8fs3LnTrF27ts7KyJ133mkqKyudj3VuvfVWU1FRYdLS0hp0fPVZQWkR34NSXzk5OXr88cc1dOhQLV26VLm5uZo9e7Y6duyoo0eP6vrrr1f37t01depUXXzxxVq1apUuv/xyDRo0SDfffLM2bdqkoUOHKi0tTfv379ekSZPUqVMnSVJUVJTeeOMNXXzxxUpISNBll12m5557TldccYVefPFFDRs2TP/xH/9RZ04rV67U1KlTtWXLlrDtMTExioiIUHV1tUKhkGpra1VbW6vY2Nif/HY9AMDPQ3x8vO6++24lJCSosLBQhw8fPunXGjRokFwul2bMmKErr7xS77//vvr371/nlt9gMKiHHnpITzzxRNjqicvlUlxcnKRvvxFekqqrqyV9e8NHY2tVH/G4XC4999xzeuKJJ+T1etW7d2/dfPPNevLJJ1VeXq6zzz5b33zzjd59913t379fU6ZMUefOnZWQkKCEhAT9/e9/1+effy5JysvL08iRI5WYmCjp25Pw9ttv66uvvtLZZ5+tqKgoXXPNNRo5cqQiIyNVXFysLl261JlTQUGBCgoK6myvqKgICyRRUVGKjIzUsWPHVFtbe3p/UACAFsEYo8WLF6tDhw66/fbbtWXLFr355pv1+kjn+1544QV5vV7de++9Kikp0fbt2/X666/Xea1jx47pz3/+8wnnUl5eLpfL5QSSmJgYSdLRo0dP4uh+XKv5T3WXy6Vp06Zp7dq1Gjp0qHbu3Kk333xTOTk5iouLU7du3RQMBhUXF6czzzxTMTExuvbaa3X77berurpawWBQvXr1Ups2bZSQkKCePXuqoqLC+aEfX+WQpLKyMoVCIc2ePVupqam67rrrNH/+fL377rt15uV2u9WjRw8ndR5XVlamL7/8Uj169FBCQoJ69eqltm3b6osvvnCSKQDg5y0QCGjBggW65557tG/fPj322GMaMGBAg18nOjpa5513nt58801dffXVeuGFF3TZZZfp97//veLj48N6IyIilJSUJK/XW2d1Ze/evaqpqdH555+v2NhY9e3bV8eOHVNxcfEpHeeJtJoVFGOMVqxYoZtvvllPPfWU1qxZo1AopH/7t3/Tl19+qfz8fO3evVvXXHONnn/+eRUWFuqXv/yl3n77bW3ZskVvvPGGfvOb36hTp06Ki4vT0KFD9T//8z/av39/nX19+OGH2rdvnx566CGlp6dr8ODBqq6u1htvvFGnd8KECbrvvvs0duxYLVmyxNleWVmp//u//9M999yjF198UR6PRy6XS0uXLj2pZAwAaJ1CoZB2796tu+66S4sWLdITTzyhMWPGhH388lNqa2s1fPhwjR49Wu+++66OHj2q+Ph4FRcX13nP6dy5s/OJwZVXXqlgMOiMrV+/Xp9//rnuvfdeDR8+XMOHD1dubu4J3ytPVatZQZGk/Px8jRs3TuvWrdOAAQM0YMAAffTRR7rhhhu0fv16vfPOO5o+fbqCwaD69OmjV199VXfddZeCwaBmz56tF154QWeffbY8Ho8ef/xx3XvvvaqpqVEgENDevXud36hcWFioiRMnaufOnUpJSdHHH3+sm266SXv27KkzpyNHjsjv99f5i2SM0TPPPKPHH39cycnJqq6u1tSpU/XRRx81yc8KAGAvY4xKSkrCVtVXrVqlxx57TElJSRo/frxcLpcOHDjghIMjR45oz549Onr0qEKhkPbv368DBw5I+jbkPPjgg1q0aJHOPfdcpaSk6L333nPeA78rFArpyy+/1Ndff13njtJ9+/Zp0qRJ2r59uy644AK9+eabuvvuu0/LRzwu0wL/cz0YDNZZkvqu49dzSN+mxu/eQuVyuRQdHS2Xy6Wampqw6z2OXwsiSTU1Nc6JiYyMVFRUlKqqqsKSZnR0tCIiIurs47uOP/f4xbDf9919VldXs3oCAJD0z/eY7773REREKDo6WqFQSNXV1c41IFVVVc7Y8febmJgYGWOcC1mlf74nSXXfH7/ru6/7Y3P7/vtofQUCAbnd7h/taZUBBQAA2Ks+AaVVfcQDAABaBwIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrNDigrFmzRiNHjlRSUpJcLpfeeOONsHFjjObOnauuXbsqLi5OaWlp2rVrV1jPoUOHNHbsWLndbiUkJGj8+PE6cuTIKR0IAABoPRocUMrLyzVgwAA9/fTTJxx/7LHHNH/+fD377LPKz89Xu3btlJ6eroqKCqdn7Nix2rZtm1auXKlly5ZpzZo1mjBhwskfBQAAaF3MKZBkXn/9dedxKBQyXq/X/O53v3O2lZWVmdjYWPPqq68aY4zZvn27kWQ2bNjg9Lz11lvG5XKZ/fv312u/gUDASKIoiqIoqgVWIBD4yff6Rr0GZc+ePfL7/UpLS3O2xcfHKzU1VXl5eZKkvLw8JSQkKCUlxelJS0tTRESE8vPzT/i6lZWVCgaDYQUAAFqvRg0ofr9fkuTxeMK2ezweZ8zv9ysxMTFsPCoqSh07dnR6vi87O1vx8fFOde/evTGnDQAALNMi7uLJyspSIBBwqri4uLmnBAAATqNGDSher1eSVFJSEra9pKTEGfN6vSotLQ0br6mp0aFDh5ye74uNjZXb7Q4rAADQejVqQOnZs6e8Xq9yc3OdbcFgUPn5+fL5fJIkn8+nsrIyFRQUOD2rVq1SKBRSampqY04HAAC0UFENfcKRI0f02WefOY/37NmjzZs3q2PHjkpOTtbUqVP18MMPq1evXurZs6fmzJmjpKQkXXXVVZKkPn366LLLLtMtt9yiZ599VtXV1Zo8ebKuvfZaJSUlNdqBAQCAFqyedxQ73nvvvRPeMjRu3DhjzLe3Gs+ZM8d4PB4TGxtrhg0bZgoLC8Ne4+uvvzZjxowx7du3N26329x4443m8OHD9Z4DtxlTFEVRVMut+txm7DLGGLUwwWBQ8fHxzT0NAABwEgKBwE9eT9oi7uIBAAA/LwQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANZpUEDJzs7WRRddpDPOOEOJiYm66qqrVFhYGNZTUVGhzMxMderUSe3bt9fo0aNVUlIS1lNUVKSMjAy1bdtWiYmJmjlzpmpqak79aAAAQKvQoICyevVqZWZmat26dVq5cqWqq6s1fPhwlZeXOz3Tpk3T0qVLlZOTo9WrV+vAgQMaNWqUM15bW6uMjAxVVVVp7dq1evnll7Vw4ULNnTu38Y4KAAC0bOYUlJaWGklm9erVxhhjysrKTHR0tMnJyXF6duzYYSSZvLw8Y4wxy5cvNxEREcbv9zs9CxYsMG6321RWVtZrv4FAwEiiKIqiKKoFViAQ+Mn3+lO6BiUQCEiSOnbsKEkqKChQdXW10tLSnJ7evXsrOTlZeXl5kqS8vDz1799fHo/H6UlPT1cwGNS2bdtOZToAAKCViDrZJ4ZCIU2dOlVDhgxRv379JEl+v18xMTFKSEgI6/V4PPL7/U7Pd8PJ8fHjYydSWVmpyspK53EwGDzZaQNoDLMkJTfDfv8qaVUz7BdAkzvpgJKZmalPPvlEH374YWPO54Sys7P1wAMPnPb9AKinNpImNfE+yyS92MT7BNBsTuojnsmTJ2vZsmV677331K1bN2e71+tVVVWVysrKwvpLSkrk9Xqdnu/f1XP88fGe78vKylIgEHCquLj4ZKYNoLG8JOmLJt7nG5I2N/E+ATSfhlwUGwqFTGZmpklKSjI7d+6sM378Itm//vWvzrZPP/3USHUvki0pKXF6nnvuOeN2u01FRUW95sFFshRlQd0v02T/+0ZGF1lwzBRFNUrV5yLZBgWUSZMmmfj4ePP++++bgwcPOnX06FGnZ+LEiSY5OdmsWrXKbNy40fh8PuPz+Zzxmpoa069fPzN8+HCzefNms2LFCtOlSxeTlZVV73kQUCjKgjpLRl+oaQLKQhlFW3DMFEU1SjV6QPmhHb300ktOz7Fjx8xtt91mOnToYNq2bWuuvvpqc/DgwbDX2bt3rxkxYoSJi4sznTt3NjNmzDDV1dX1ngcBhaIsqft1+sNJmVg9oahWVvUJKK7/HzxalGAwqPj4+OaeBoCzJK3W6b2j538k3Syp+jTuA0CTCgQCcrvdP9rD7+IBcPL2Slp4Gl8/IOkpEU6AnyECCoBT85KkotP02m+KO3eAnykCCoBTs1enZxUlKFZPgJ8xAgqAU/eSpMb+eiJWT4CfNQIKgFP3hb4NKY0lKOlJsXoC/IwRUACcOqPGXUV5Q6yeAD9zBBQAjeMLNc61KIfFtScACCgAGonRt7/Mb98pvg7XngAQAQVAYzrVa1EOi2tPAEgioABoTMdXUfaf5POXiNUTAJIIKAAa28lei3JE0nxJVY06GwAtFAEFQOMykv6khq+icO0JgO8goABofA1dRWH1BMD3EFAAND4j6b8lHahnP9eeAPgeAgqA02Ov6reKUi5WTwDUQUABcHocvxbl4E/0LZH08emfDoCWhYAC4PTZqx9fRTkq6Y9i9QRAHQQUAKePkfSCfngVhdUTAD+AgALg9PpC0ssn2M7qCYAfQUABcHqFJD0vyf+97UskbWr66QBoGQgoAE6/738vyjGxegLgRxFQAJx+x1dRSv7/Y1ZPAPwEAgqApnF8FYXVEwD1ENXcEwDwMxGStEDS15IKmnkuAKxHQAHQdL6Q9LvmngSAloCPeAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACs06CAsmDBAl1wwQVyu91yu93y+Xx66623nPGKigplZmaqU6dOat++vUaPHq2SkpKw1ygqKlJGRobatm2rxMREzZw5UzU1NY1zNAAAoFVoUEDp1q2b5s2bp4KCAm3cuFGXXnqprrzySm3btk2SNG3aNC1dulQ5OTlavXq1Dhw4oFGjRjnPr62tVUZGhqqqqrR27Vq9/PLLWrhwoebOndu4RwUAAFo2c4o6dOhg/vSnP5mysjITHR1tcnJynLEdO3YYSSYvL88YY8zy5ctNRESE8fv9Ts+CBQuM2+02lZWV9d5nIBAwkiiKoiiKaoEVCAR+8r3+pK9Bqa2t1eLFi1VeXi6fz6eCggJVV1crLS3N6endu7eSk5OVl5cnScrLy1P//v3l8XicnvT0dAWDQWcV5kQqKysVDAbDCgAAtF4NDihbt25V+/btFRsbq4kTJ+r1119X37595ff7FRMTo4SEhLB+j8cjv98vSfL7/WHh5Pj48bEfkp2drfj4eKe6d+/e0GkDAIAWpMEB5bzzztPmzZuVn5+vSZMmady4cdq+ffvpmJsjKytLgUDAqeLi4tO6PwAA0LyiGvqEmJgYnXvuuZKkQYMGacOGDfrjH/+o3/zmN6qqqlJZWVnYKkpJSYm8Xq8kyev1av369WGvd/wun+M9JxIbG6vY2NiGThUAALRQp/w9KKFQSJWVlRo0aJCio6OVm5vrjBUWFqqoqEg+n0+S5PP5tHXrVpWWljo9K1eulNvtVt++fU91KgAAoLVowA07ZtasWWb16tVmz5495h//+IeZNWuWcblc5p133jHGGDNx4kSTnJxsVq1aZTZu3Gh8Pp/x+XzO82tqaky/fv3M8OHDzebNm82KFStMly5dTFZWVkOmwV08FEVRFNWCqz538TQooNx0002mR48eJiYmxnTp0sUMGzbMCSfGGHPs2DFz2223mQ4dOpi2bduaq6++2hw8eDDsNfbu3WtGjBhh4uLiTOfOnc2MGTNMdXV1Q6ZBQKEoiqKoFlz1CSguY4xRCxMMBhUfH9/c0wAAACchEAjI7Xb/aA+/iwcAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOqcUUObNmyeXy6WpU6c62yoqKpSZmalOnTqpffv2Gj16tEpKSsKeV1RUpIyMDLVt21aJiYmaOXOmampqTmUqAACgFTnpgLJhwwY999xzuuCCC8K2T5s2TUuXLlVOTo5Wr16tAwcOaNSoUc54bW2tMjIyVFVVpbVr1+rll1/WwoULNXfu3JM/CgAA0LqYk3D48GHTq1cvs3LlSvOLX/zCTJkyxRhjTFlZmYmOjjY5OTlO744dO4wkk5eXZ4wxZvny5SYiIsL4/X6nZ8GCBcbtdpvKysp67T8QCBhJFEVRFEW1wAoEAj/5Xn9SKyiZmZnKyMhQWlpa2PaCggJVV1eHbe/du7eSk5OVl5cnScrLy1P//v3l8XicnvT0dAWDQW3btu1kpgMAAFqZqIY+YfHixdq0aZM2bNhQZ8zv9ysmJkYJCQlh2z0ej/x+v9Pz3XByfPz42IlUVlaqsrLSeRwMBhs6bQAA0II0aAWluLhYU6ZM0aJFi9SmTZvTNac6srOzFR8f71T37t2bbN8AAKDpNSigFBQUqLS0VBdeeKGioqIUFRWl1atXa/78+YqKipLH41FVVZXKysrCnldSUiKv1ytJ8nq9de7qOf74eM/3ZWVlKRAIOFVcXNyQaQMAgBamQQFl2LBh2rp1qzZv3uxUSkqKxo4d6/w5Ojpaubm5znMKCwtVVFQkn88nSfL5fNq6datKS0udnpUrV8rtdqtv374n3G9sbKzcbndYAQCAVqwBN++c0Hfv4jHGmIkTJ5rk5GSzatUqs3HjRuPz+YzP53PGa2pqTL9+/czw4cPN5s2bzYoVK0yXLl1MVlZWvffJXTwURVEU1XKrPnfxNPgi2Z/yxBNPKCIiQqNHj1ZlZaXS09P1zDPPOOORkZFatmyZJk2aJJ/Pp3bt2mncuHF68MEHG3sqAACghXIZY0xzT6KhgsGg4uPjm3saAADgJAQCgZ+8XIPfxQMAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwToMCyv333y+XyxVWvXv3dsYrKiqUmZmpTp06qX379ho9erRKSkrCXqOoqEgZGRlq27atEhMTNXPmTNXU1DTO0QAAgFYhqqFPOP/88/Xuu+/+8wWi/vkS06ZN09///nfl5OQoPj5ekydP1qhRo/TRRx9Jkmpra5WRkSGv16u1a9fq4MGD+q//+i9FR0fr0UcfbYTDAQAArYJpgPvuu88MGDDghGNlZWUmOjra5OTkONt27NhhJJm8vDxjjDHLly83ERERxu/3Oz0LFiwwbrfbVFZW1nsegUDASKIoiqIoqgVWIBD4yff6Bq+g7Nq1S0lJSWrTpo18Pp+ys7OVnJysgoICVVdXKy0tzent3bu3kpOTlZeXp4svvlh5eXnq37+/PB6P05Oenq5JkyZp27ZtGjhw4An3WVlZqcrKSudxMBiUJF1++eWKjo5u6CEAAIBmUF1drWXLltWrt0EBJTU1VQsXLtR5552ngwcP6oEHHtC//uu/6pNPPpHf71dMTIwSEhLCnuPxeOT3+yVJfr8/LJwcHz8+9kOys7P1wAMP1Nl+6623ql27dg05BAAA0EzKy8tPT0AZMWKE8+cLLrhAqamp6tGjh1577TXFxcU1bJYNkJWVpenTpzuPg8Ggunfvftr2BwAAmtcp3WackJCgf/mXf9Fnn30mr9erqqoqlZWVhfWUlJTI6/VKkrxeb527eo4/Pt5zIrGxsXK73WEFAABar1MKKEeOHNHnn3+url27atCgQYqOjlZubq4zXlhYqKKiIvl8PkmSz+fT1q1bVVpa6vSsXLlSbrdbffv2PZWpAACAVqRBH/HceeedGjlypHr06KEDBw7ovvvuU2RkpMaMGaP4+HiNHz9e06dPV8eOHeV2u3X77bfL5/Pp4osvliQNHz5cffv21fXXX6/HHntMfr9f9957rzIzMxUbG3taDhAAALQ8DQoo+/bt05gxY/T111+rS5cuGjp0qNatW6cuXbpIkp544glFRERo9OjRqqysVHp6up555hnn+ZGRkVq2bJkmTZokn8+ndu3aady4cXrwwQcb96gAAECL5jLGmOaeREMFg0HFx8dr6dKl3MUDAEALUV5erpEjRyoQCPzk9aT8Lh4AAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdRocUPbv36/rrrtOnTp1UlxcnPr376+NGzc648YYzZ07V127dlVcXJzS0tK0a9eusNc4dOiQxo4dK7fbrYSEBI0fP15Hjhw59aMBAACtQoMCyjfffKMhQ4YoOjpab731lrZv367f//736tChg9Pz2GOPaf78+Xr22WeVn5+vdu3aKT09XRUVFU7P2LFjtW3bNq1cuVLLli3TmjVrNGHChMY7KgAA0KK5jDGmvs2zZs3SRx99pA8++OCE48YYJSUlacaMGbrzzjslSYFAQB6PRwsXLtS1116rHTt2qG/fvtqwYYNSUlIkSStWrNCvfvUr7du3T0lJST85j2AwqPj4eC1dulTt2rWr7/QBAEAzKi8v18iRIxUIBOR2u3+0t0ErKEuWLFFKSop+/etfKzExUQMHDtQLL7zgjO/Zs0d+v19paWnOtvj4eKWmpiovL0+SlJeXp4SEBCecSFJaWpoiIiKUn59/wv1WVlYqGAyGFQAAaL0aFFB2796tBQsWqFevXnr77bc1adIk3XHHHXr55ZclSX6/X5Lk8XjCnufxeJwxv9+vxMTEsPGoqCh17NjR6fm+7OxsxcfHO9W9e/eGTBsAALQwDQoooVBIF154oR599FENHDhQEyZM0C233KJnn332dM1PkpSVlaVAIOBUcXHxad0fAABoXg0KKF27dlXfvn3DtvXp00dFRUWSJK/XK0kqKSkJ6ykpKXHGvF6vSktLw8Zramp06NAhp+f7YmNj5Xa7wwoAALReDQooQ4YMUWFhYdi2nTt3qkePHpKknj17yuv1Kjc31xkPBoPKz8+Xz+eTJPl8PpWVlamgoMDpWbVqlUKhkFJTU0/6QAAAQOsR1ZDmadOm6ZJLLtGjjz6qa665RuvXr9fzzz+v559/XpLkcrk0depUPfzww+rVq5d69uypOXPmKCkpSVdddZWkb1dcLrvsMuejoerqak2ePFnXXnttve7gAQAArV+DAspFF12k119/XVlZWXrwwQfVs2dP/eEPf9DYsWOdnrvuukvl5eWaMGGCysrKNHToUK1YsUJt2rRxehYtWqTJkydr2LBhioiI0OjRozV//vzGOyoAANCiNeh7UGzB96AAANDynLbvQQEAAGgKBBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOlHNPYGTYYyRJB09erSZZwIAAOrr+Pv28ffxH+My9emyzO7du3XOOec09zQAAMBJKC4uVrdu3X60p0WuoHTs2FGSVFRUpPj4+GaeDYLBoLp3767i4mK53e7mns7PGufCHpwLe3Au7GGM0eHDh5WUlPSTvS0yoEREfHvpTHx8PH/ZLOJ2uzkfluBc2INzYQ/OhR3qu7DARbIAAMA6BBQAAGCdFhlQYmNjdd999yk2Nra5pwJxPmzCubAH58IenIuWqUXexQMAAFq3FrmCAgAAWjcCCgAAsA4BBQAAWIeAAgAArNMiA8rTTz+ts846S23atFFqaqrWr1/f3FNqVbKzs3XRRRfpjDPOUGJioq666ioVFhaG9VRUVCgzM1OdOnVS+/btNXr0aJWUlIT1FBUVKSMjQ23btlViYqJmzpypmpqapjyUVmfevHlyuVyaOnWqs41z0bT279+v6667Tp06dVJcXJz69++vjRs3OuPGGM2dO1ddu3ZVXFyc0tLStGvXrrDXOHTokMaOHSu3262EhASNHz9eR44caepDadFqa2s1Z84c9ezZU3FxcTrnnHP00EMPhf2OF85FC2damMWLF5uYmBjz4osvmm3btplbbrnFJCQkmJKSkuaeWquRnp5uXnrpJfPJJ5+YzZs3m1/96lcmOTnZHDlyxOmZOHGi6d69u8nNzTUbN240F198sbnkkkuc8ZqaGtOvXz+TlpZmPv74Y7N8+XLTuXNnk5WV1RyH1CqsX7/enHXWWeaCCy4wU6ZMcbZzLprOoUOHTI8ePcwNN9xg8vPzze7du83bb79tPvvsM6dn3rx5Jj4+3rzxxhtmy5Yt5oorrjA9e/Y0x44dc3ouu+wyM2DAALNu3TrzwQcfmHPPPdeMGTOmOQ6pxXrkkUdMp06dzLJly8yePXtMTk6Oad++vfnjH//o9HAuWrYWF1AGDx5sMjMznce1tbUmKSnJZGdnN+OsWrfS0lIjyaxevdoYY0xZWZmJjo42OTk5Ts+OHTuMJJOXl2eMMWb58uUmIiLC+P1+p2fBggXG7XabysrKpj2AVuDw4cOmV69eZuXKleYXv/iFE1A4F03r7rvvNkOHDv3B8VAoZLxer/nd737nbCsrKzOxsbHm1VdfNcYYs337diPJbNiwwel56623jMvlMvv37z99k29lMjIyzE033RS2bdSoUWbs2LHGGM5Fa9CiPuKpqqpSQUGB0tLSnG0RERFKS0tTXl5eM86sdQsEApL++UsaCwoKVF1dHXYeevfureTkZOc85OXlqX///vJ4PE5Penq6gsGgtm3b1oSzbx0yMzOVkZER9jOXOBdNbcmSJUpJSdGvf/1rJSYmauDAgXrhhRec8T179sjv94edj/j4eKWmpoadj4SEBKWkpDg9aWlpioiIUH5+ftMdTAt3ySWXKDc3Vzt37pQkbdmyRR9++KFGjBghiXPRGrSoXxb41Vdfqba2NuwfWknyeDz69NNPm2lWrVsoFNLUqVM1ZMgQ9evXT5Lk9/sVExOjhISEsF6PxyO/3+/0nOg8HR9D/S1evFibNm3Shg0b6oxxLprW7t27tWDBAk2fPl333HOPNmzYoDvuuEMxMTEaN26c8/M80c/7u+cjMTExbDwqKkodO3bkfDTArFmzFAwG1bt3b0VGRqq2tlaPPPKIxo4dK0mci1agRQUUNL3MzEx98skn+vDDD5t7Kj9LxcXFmjJlilauXKk2bdo093R+9kKhkFJSUvToo49KkgYOHKhPPvlEzz77rMaNG9fMs/t5ee2117Ro0SK98sorOv/887V582ZNnTpVSUlJnItWokV9xNO5c2dFRkbWuUOhpKREXq+3mWbVek2ePFnLli3Te++9p27dujnbvV6vqqqqVFZWFtb/3fPg9XpPeJ6Oj6F+CgoKVFpaqgsvvFBRUVGKiorS6tWrNX/+fEVFRcnj8XAumlDXrl3Vt2/fsG19+vRRUVGRpH/+PH/s3yiv16vS0tKw8ZqaGh06dIjz0QAzZ87UrFmzdO2116p///66/vrrNW3aNGVnZ0viXLQGLSqgxMTEaNCgQcrNzXW2hUIh5ebmyufzNePMWhdjjCZPnqzXX39dq1atUs+ePcPGBw0apOjo6LDzUFhYqKKiIuc8+Hw+bd26Nez//CtXrpTb7a7zDzx+2LBhw7R161Zt3rzZqZSUFI0dO9b5M+ei6QwZMqTOLfc7d+5Ujx49JEk9e/aU1+sNOx/BYFD5+flh56OsrEwFBQVOz6pVqxQKhZSamtoER9E6HD16VBER4W9hkZGRCoVCkjgXrUJzX6XbUIsXLzaxsbFm4cKFZvv27WbChAkmISEh7A4FnJpJkyaZ+Ph48/7775uDBw86dfToUadn4sSJJjk52axatcps3LjR+Hw+4/P5nPHjt7YOHz7cbN682axYscJ06dKFW1sbwXfv4jGGc9GU1q9fb6Kioswjjzxidu3aZRYtWmTatm1r/vd//9fpmTdvnklISDBvvvmm+cc//mGuvPLKE97aOnDgQJOfn28+/PBD06tXL25tbaBx48aZM88807nN+G9/+5vp3Lmzueuuu5wezkXL1uICijHGPPnkkyY5OdnExMSYwYMHm3Xr1jX3lFoVSSesl156yek5duyYue2220yHDh1M27ZtzdVXX20OHjwY9jp79+41I0aMMHFxcaZz585mxowZprq6uomPpvX5fkDhXDStpUuXmn79+pnY2FjTu3dv8/zzz4eNh0IhM2fOHOPxeExsbKwZNmyYKSwsDOv5+uuvzZgxY0z79u2N2+02N954ozl8+HBTHkaLFwwGzZQpU0xycrJp06aNOfvss83s2bPDbp3nXLRsLmO+87V7AAAAFmhR16AAAICfBwIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKzz/wCmzJmDBTvU4QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.step(0)[0]\n",
    "img = plt.imshow(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:(1) Score:(7) Reward:(-1006)\n",
      "Episode:(2) Score:(7) Reward:(-40)\n",
      "Episode:(3) Score:(12) Reward:(-1770)\n",
      "Episode:(4) Score:(2) Reward:(14)\n",
      "Episode:(5) Score:(0) Reward:(4)\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "env = TribounceEnv(render=True)\n",
    "for episode in range(1,episodes+1):\n",
    "    state,_ = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = Discrete(3).sample()\n",
    "        state,reward,_,done,info = env.step(action=action)\n",
    "    print(f\"Episode:({episode}) Score:({info['score']}) Reward:({reward})\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks Nicholas :\n",
    "\n",
    "class TrainAndLoggingCallBack(BaseCallback):\n",
    "    def __init__(self,check_freq,save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallBack,self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path,exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path,f'best_model_{self.n_calls}')\n",
    "            self.model.save(model_path)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point_dir = './train/train_basic'\n",
    "log_dir = './logs/log_basic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallBack(check_freq=50000,save_path=check_point_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TRAINING THE MODEL\n",
    "\n",
    "env = TribounceEnv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.24 GiB (GPU 0; 4.00 GiB total capacity; 2.49 GiB already allocated; 0 bytes free; 2.51 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m PPO(\u001b[39m'\u001b[39;49m\u001b[39mCnnPolicy\u001b[39;49m\u001b[39m'\u001b[39;49m,env,verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,tensorboard_log\u001b[39m=\u001b[39;49mlog_dir,learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.0002\u001b[39;49m,n_steps\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,)\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:164\u001b[0m, in \u001b[0;36mPPO.__init__\u001b[1;34m(self, policy, env, learning_rate, n_steps, batch_size, n_epochs, gamma, gae_lambda, clip_range, clip_range_vf, normalize_advantage, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, target_kl, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_kl \u001b[39m=\u001b[39m target_kl\n\u001b[0;32m    163\u001b[0m \u001b[39mif\u001b[39;00m _init_setup_model:\n\u001b[1;32m--> 164\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_model()\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:167\u001b[0m, in \u001b[0;36mPPO._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_setup_model\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_setup_model()\n\u001b[0;32m    169\u001b[0m     \u001b[39m# Initialize schedules for policy/value clipping\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclip_range \u001b[39m=\u001b[39m get_schedule_fn(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclip_range)\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:127\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy_class(  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    124\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_space, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_schedule, use_sde\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_sde, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy_kwargs\n\u001b[0;32m    125\u001b[0m )\n\u001b[0;32m    126\u001b[0m \u001b[39m# pytype:enable=not-instantiable\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.24 GiB (GPU 0; 4.00 GiB total capacity; 2.49 GiB already allocated; 0 bytes free; 2.51 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model = PPO('CnnPolicy',env,verbose=1,tensorboard_log=log_dir,learning_rate=0.0002,n_steps=64,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_basic\\PPO_5\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 16.0 GiB for an array with shape (2048, 1, 3, 700, 1000) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m300000\u001b[39;49m,callback\u001b[39m=\u001b[39;49mcallback)\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[0;32m    300\u001b[0m     \u001b[39mself\u001b[39m: SelfPPO,\n\u001b[0;32m    301\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    307\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 308\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[0;32m    309\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[0;32m    310\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    311\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[0;32m    312\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[0;32m    313\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[0;32m    314\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m    315\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:259\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 259\u001b[0m     continue_training \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv, callback, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrollout_buffer, n_rollout_steps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_steps)\n\u001b[0;32m    261\u001b[0m     \u001b[39mif\u001b[39;00m continue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:154\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39mset_training_mode(\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    153\u001b[0m n_steps \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 154\u001b[0m rollout_buffer\u001b[39m.\u001b[39;49mreset()\n\u001b[0;32m    155\u001b[0m \u001b[39m# Sample new weights for the state dependent exploration\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_sde:\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\buffers.py:364\u001b[0m, in \u001b[0;36mRolloutBuffer.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreset\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 364\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservations \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mzeros((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuffer_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_envs, \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobs_shape), dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat32)\n\u001b[0;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_envs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dim), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m    366\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrewards \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_envs), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 16.0 GiB for an array with shape (2048, 1, 3, 700, 1000) and data type float32"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=300000,callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Training\\Saved Models\\CNNnoGRAY.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env= TribounceEnv(render=True)\n",
    "evaluate_policy(model,env,n_eval_episodes=5)\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:(1) Score:(7) Reward:(-1093)\n",
      "Episode:(2) Score:(0) Reward:(0)\n",
      "Episode:(3) Score:(0) Reward:(0)\n",
      "Episode:(4) Score:(0) Reward:(0)\n",
      "Episode:(5) Score:(0) Reward:(0)\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "env = TribounceEnv(render=True)\n",
    "for episode in range(1,episodes+1):\n",
    "    state,_ = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action,_ = model.predict(state)\n",
    "        state,reward,_,done,info = env.step(action=action)\n",
    "    print(f\"Episode:({episode}) Score:({info['score']}) Reward:({reward})\")\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
