{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete,Box,Dict,Tuple,MultiBinary,MultiDiscrete\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "import os\n",
    "import pygame\n",
    "import random as rn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TribounceEnv(Env):\n",
    "    def __init__(self):\n",
    "\n",
    "        self.width,self.height = 1000,700\n",
    "        self.moveRight= False \n",
    "        self.moveLeft = False \n",
    "\n",
    "        self.jump = False\n",
    "        self.jumpe = False\n",
    "        self.goingUp = True\n",
    "        self.goingUpSpeed = 11.0\n",
    "        self.gravitationalAccelartion = 0.2\n",
    "        \n",
    "        self.playerSpeed = 6\n",
    "\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        self.playerPos = [self.width/2,self.height-200]\n",
    "        self.playerHeight = 60\n",
    "        \n",
    "        self.enemyStats = []\n",
    "        \n",
    "        self.enemySpeed = 5\n",
    "\n",
    "        self.kills = 0\n",
    "\n",
    "        self.fps = 120\n",
    "        self.fpsCount = 0\n",
    "        self.time = 0  \n",
    "\n",
    "        self.reward = 0   \n",
    "\n",
    "        self.action_space = Discrete(3)# have 3 valuse to be controlled\n",
    "        self.observation_space = Box(low=0,high=self.width,shape=(2,2))\n",
    "        self.state = np.array([self.playerPos,[0,self.width]])\n",
    "\n",
    "\n",
    "\n",
    "    def state(self,action):\n",
    "\n",
    "        nearEnemy = []\n",
    "\n",
    "        if action == 0:\n",
    "            self.moveLeft = True\n",
    "            self.moveRight = False\n",
    "        elif action == 1:\n",
    "            self.moveLeft = False\n",
    "            self.moveRight = True\n",
    "        if action == 2 and self.height-205<self.playerPos[1]<self.height-195:\n",
    "            self.jump = True\n",
    "        elif action != 2 and self.height-202<self.playerPos[1]<self.height-198:\n",
    "            self.jump = False\n",
    "\n",
    "        if self.jump and round(self.goingUpSpeed,1) > -11.0 + self.gravitationalAccelartion:\n",
    "            self.goingUpSpeed -=self.gravitationalAccelartion\n",
    "        elif self.jump :\n",
    "            self.jump = False\n",
    "            self.jumpe = False\n",
    "            self.goingUpSpeed = 11.0\n",
    "            self.playerPos[1] = self.height-200\n",
    "\n",
    "        if self.jump:\n",
    "            self.playerPos[1]-=self.goingUpSpeed\n",
    "\n",
    "        if self.jumpe and round(self.goingUpSpeed,1) > -11.6 + self.gravitationalAccelartion:\n",
    "            self.goingUpSpeed -=self.gravitationalAccelartion\n",
    "            self.jump = False\n",
    "        elif self.jumpe :\n",
    "            self.jumpe = False\n",
    "            \n",
    "            self.goingUpSpeed = 11.0\n",
    "            self.playerPos[1] = self.height-200\n",
    "\n",
    "        if self.playerPos[0]> self.width - self.playerHeight/2:\n",
    "            self.playerPos[0] = self.width-self.playerHeight/2\n",
    "        elif self.playerPos[0]< self.playerHeight/2:\n",
    "            self.playerPos[0] = self.playerHeight/2\n",
    "\n",
    "        if self.time > 2 and self.fpsCount%(1.7*self.fps)== 0:\n",
    "            ran = rn.randint(0,1)\n",
    "            if ran == 0:\n",
    "                self.enemyStats.append([[self.width-40,self.height-200],1,ran])\n",
    "            else:\n",
    "                self.enemyStats.append([[40,self.height-200],1,ran])\n",
    "\n",
    "        \n",
    "        for e in self.enemyStats:\n",
    "            # print(self.playerPos,[e[0][0],e[0][1]-40], self.goingUpSpeed<0)\n",
    "\n",
    "            if (e[0][0]-5 - 40<=self.playerPos[0]<=e[0][0]+5+40) and (e[0][1]  - 1 - 80<= self.playerPos[1] <= e[0][1] + 1 - 80) and self.goingUpSpeed<0 :\n",
    "                e[1] = 0\n",
    "                self.jumpe = True \n",
    "                self.goingUpSpeed = 10.0\n",
    "                self.kills +=1\n",
    "                self.reward +=10\n",
    "        \n",
    "\n",
    "            # if (e[0]- triwe/2 <= trix <= e[0]+triwe/2) and (self.height - rectw - triwe/2 <= triy <= self.height - rectw + triwe/2):\n",
    "            elif (e[0][0]-2-40-self.playerHeight/2 <= self.playerPos[0] <= e[0][0]+2+40+self.playerHeight/2) and (self.height-200 - 80 - 2 <= self.playerPos[1]<=self.height-200 + 2) :\n",
    "                done= True\n",
    "            \n",
    "            else:\n",
    "                done = False\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "            if e[0][0] <= 40:\n",
    "                e[2] = 1 \n",
    "            elif e[0][0] >= self.width - 40:\n",
    "                e[2] = 0 \n",
    "\n",
    "            if e[2] == 1:\n",
    "                e[0][0] += self.enemySpeed\n",
    "            elif e[2] == 0:\n",
    "                e[0][0] -= self.enemySpeed\n",
    "\n",
    "            if e[1] == 0:\n",
    "                self.enemyStats.remove(e)\n",
    "\n",
    "\n",
    "            nearEnemy.append(e[0]-self.playerPos[0])\n",
    "\n",
    "        self.fpsCount +=1\n",
    "        if self.fpsCount%self.fps == 0:\n",
    "            self.enemySpeed+=0.1\n",
    "            self.time+=1\n",
    "            self.reward += self.time\n",
    "\n",
    "        nearEnemy.sort()\n",
    "        \n",
    "        self.state = np.array([self.playerPos,[len(self.enemyStats),nearEnemy]])\n",
    "        info = {}\n",
    "        self.clock.tick(self.fps) \n",
    "       \n",
    "        _ = True\n",
    "\n",
    "        return self.state , self.reward , done,_ , info\n",
    "    \n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "        \n",
    "                    \n",
    "    def reset(self):\n",
    "        self.state = np.array([self.playerPos,[0,self.width]])\n",
    "\n",
    "        self.moveRight = False \n",
    "        self.moveLeft = False \n",
    "\n",
    "        self.jump = False\n",
    "        self.jumpe = False\n",
    "        self.goingUp = True\n",
    "        self.goingUpSpeed = 11.0\n",
    "        \n",
    "        self.playerSpeed = 6\n",
    "\n",
    "        self.playerPos = [self.width/2,self.height-200]\n",
    "        \n",
    "        self.enemyStats = [[[0,0],0,0]]\n",
    "        self.enemySpeed = 5\n",
    "\n",
    "        self.kills = 0\n",
    "        self.fpsCount = 0\n",
    "        self.time = 0  \n",
    "\n",
    "        self.reward = 0  \n",
    "        return self.state\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TribounceEnv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[592.86523, 860.2477 ],\n",
       "       [393.09454, 125.39939]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = DummyVecEnv([lambda:env])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('Training','Logs')\n",
    "model = PPO('MlpPolicy',env,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[0;32m    300\u001b[0m     \u001b[39mself\u001b[39m: SelfPPO,\n\u001b[0;32m    301\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    307\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 308\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[0;32m    309\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[0;32m    310\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    311\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[0;32m    312\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[0;32m    313\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[0;32m    314\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m    315\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:259\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 259\u001b[0m     continue_training \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv, callback, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrollout_buffer, n_rollout_steps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_steps)\n\u001b[0;32m    261\u001b[0m     \u001b[39mif\u001b[39;00m continue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:178\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space, spaces\u001b[39m.\u001b[39mBox):\n\u001b[0;32m    176\u001b[0m     clipped_actions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mclip(actions, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mlow, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mhigh)\n\u001b[1;32m--> 178\u001b[0m new_obs, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(clipped_actions)\n\u001b[0;32m    180\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mnum_envs\n\u001b[0;32m    182\u001b[0m \u001b[39m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:197\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \n\u001b[0;32m    193\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 197\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     56\u001b[0m     \u001b[39m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[1;32m---> 58\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvs[env_idx]\u001b[39m.\u001b[39;49mstep(\n\u001b[0;32m     59\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactions[env_idx]\n\u001b[0;32m     60\u001b[0m         )\n\u001b[0;32m     61\u001b[0m         \u001b[39m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx] \u001b[39m=\u001b[39m terminated \u001b[39mor\u001b[39;00m truncated\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shimmy\\openai_gym_compatibility.py:255\u001b[0m, in \u001b[0;36mGymV21CompatibilityV0.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action: ActType) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[Any, \u001b[39mfloat\u001b[39m, \u001b[39mbool\u001b[39m, \u001b[39mbool\u001b[39m, \u001b[39mdict\u001b[39m]:\n\u001b[0;32m    247\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Steps through the environment.\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \n\u001b[0;32m    249\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39m        (observation, reward, terminated, truncated, info)\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 255\u001b[0m     obs, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgym_env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m    257\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender()\n",
      "File \u001b[1;32mc:\\Users\\arya2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\core.py:115\u001b[0m, in \u001b[0;36mEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action: ActType) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[ObsType, \u001b[39mfloat\u001b[39m, \u001b[39mbool\u001b[39m, \u001b[39mbool\u001b[39m, \u001b[39mdict\u001b[39m]:\n\u001b[0;32m     87\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run one timestep of the environment's dynamics.\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \n\u001b[0;32m     89\u001b[0m \u001b[39m    When end of episode is reached, you are responsible for calling :meth:`reset` to reset this environment's state.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39m            a certain timelimit was exceeded, or the physics simulation has entered an invalid state.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
